---
title: "Reinforcement Learning as Iterative and Amortised Inference"
collection: publications
permalink: /publication/cai
excerpt: 
date: 2020-06-23
venue: ArXiv
paperurl: 'https://arxiv.org/abs/2006.12964'
---

_Beren Millidge,_ __Alexander Tschantz__, _Anil K. Seth, Christopher L Buckley_

[[Paper](https://arxiv.org/abs/2006.12964)] 

Active Inference (AIF) is an emerging framework in the brain sciences which suggests that biological agents act to minimise a variational bound on model evidence. Control-as-Inference (CAI) is a framework within reinforcement learning which casts decision making as a variational inference problem. While these frameworks both consider action selection through the lens of variational inference, their relationship remains unclear. Here, we provide a formal comparison between them and demonstrate that the primary difference arises from how value is incorporated into their respective generative models. In the context of this comparison, we highlight several ways in which these frameworks can inform one another.

